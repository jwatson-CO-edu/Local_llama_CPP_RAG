{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a32057c-f5bd-4aea-a78f-9bb14b28f510",
   "metadata": {},
   "source": [
    "## Copy PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8219dcd5-258d-4463-bb82-bcafaa104e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n"
     ]
    }
   ],
   "source": [
    "from os import environ, path\n",
    "import time, sys\n",
    "now = time.time\n",
    "from aa_scrape_PDF import copy_pdfs\n",
    "\n",
    "environ[\"_RAG_PDF_SOURCE\"] = \"/media/james/FILEPILE/$_Robust_Planning/Literature/References/storage\"\n",
    "environ[\"_RAG_PDF_DESTIN\"] = \"data/input/pdf\"\n",
    "environ[\"_RAG_VERBOSE\"]    =    \"\"\n",
    "environ[\"_RAG_DOC_ADD\"]    =  \"50\"\n",
    "environ[\"_RAG_DOC_LIMIT\"]  = \"250\"\n",
    "environ[\"_RAG_DOC_DBASE\"]  = \"lit_pdf\"\n",
    "environ[\"_RAG_VEC_DBASE\"]  = \"lit_vec\"\n",
    "copy_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335fa2a-8447-41b8-aca7-c2b31156624d",
   "metadata": {},
   "source": [
    "## Check existence of the database and Determine if more docs will be loaded this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbdc4e5-3a46-4aab-88af-f79effbeb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "sys.modules['sqlite3'] = sys.modules.pop( 'pysqlite3' )\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4 as gen_id\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection        = persistent_client.get_or_create_collection( environ[\"_RAG_DOC_DBASE\"] )\n",
    "\n",
    "if environ[\"_RAG_DOC_DBASE\"] in [c.name for c in persistent_client.list_collections()]:\n",
    "    environ[\"_RAG_DOCDB_EXISTS\"] = \"1\"\n",
    "else:\n",
    "    environ[\"_RAG_DOCDB_EXISTS\"] = \"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e6e62-cb9b-4178-9ea4-a9d9e7c31410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639c8cf-1b5f-4c89-809a-ad16c7856963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97b97eeb-bbeb-4b40-b0a2-61b8f7643707",
   "metadata": {},
   "source": [
    "## Load PDFs by page chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393314ba-7acb-46bf-bfb8-640e72407061",
   "metadata": {},
   "source": [
    "### https://python.langchain.com/docs/how_to/document_loader_pdf/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5b7d6-c463-4917-89e4-f1aa6c040058",
   "metadata": {},
   "source": [
    "* `python3.10 -m pip install pypdf langchain-unstructured \"unstructured[pdf]\" --user`\n",
    "* `apt install tesseract-ocr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a2cca2-b617-4243-9e82-82e26de66e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "if not environ[\"_RAG_DOCDB_EXISTS\"]:\n",
    "    bgn = now()\n",
    "    pdfs_drct = environ[\"_RAG_PDF_DESTIN\"]\n",
    "    fNames    = [item for item in os.listdir( pdfs_drct ) if (str( item ).split('.')[-1].lower() == 'pdf')]\n",
    "    print( f\"Copied {len(fNames)} files!\" )\n",
    "    pages = deque() # Fast append\n",
    "    \n",
    "    for i, fNam in enumerate( fNames ):\n",
    "        file_path = path.join( pdfs_drct, fNam )\n",
    "        loader    = PyPDFLoader( file_path )\n",
    "        async for page in loader.alazy_load():\n",
    "            pages.append( page )\n",
    "        print( f\"{i+1}:{len(pages)}\", end = ', ', flush = True )\n",
    "    print()\n",
    "    pages = list( pages )\n",
    "    print( f\"Read {len(pages)} pages in {(now()-bgn)/60.0} minutes!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e216559a-5e4b-4d21-a8ff-6d796e0c5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{pages[0].metadata}\\n\")\n",
    "# print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0be2b0-5b1c-4838-b4db-62b518afeac4",
   "metadata": {},
   "source": [
    "## Load the text embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9faaf3ef-1701-49c5-a781-d9e551346763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_ollama_model( modelStr ):\n",
    "    \"\"\" Pull a named model from Ollama and store it wherever \"\"\"\n",
    "    print( f\"About to save '{modelStr}'.\\nThis will spew a lot of text on the first run...\" )\n",
    "    os.system( f\"ollama pull {modelStr}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35da1790-0281-4af3-8b81-88560fc16a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to save 'nomic-embed-text'.\n",
      "This will spew a lot of text on the first run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os, time\n",
    "now = time.time\n",
    "\n",
    "\n",
    "# from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "# from langchain_community import embeddings\n",
    "\n",
    "pull_ollama_model( \"nomic-embed-text\" )\n",
    "\n",
    "local_embeddings = OllamaEmbeddings( model = \"nomic-embed-text\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd67496-84af-4d78-8e3d-1284822eed3a",
   "metadata": {},
   "source": [
    "## Populate document database (of pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571f7d54-8795-4b9b-8a8c-66459c4e9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not environ[\"_RAG_DOCDB_EXISTS\"]:\n",
    "    bgn = now()\n",
    "    docIDs = [str( gen_id() ) for _ in range( len(pages) )]\n",
    "    dcmnts = [str( pg.page_content ) for pg in pages]\n",
    "    collection.add(\n",
    "        ids       = docIDs, \n",
    "        documents = dcmnts\n",
    "    )\n",
    "    print( f\"Added {len(dcmnts)} documents in {(now()-bgn)/60.0} minutes!\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c3459-9cfc-4e17-b249-172bce6cdf2a",
   "metadata": {},
   "source": [
    "# Create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5000e0-162c-4f28-9f2b-1e896f42f924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built vector store in 0.00527191162109375 seconds!\n"
     ]
    }
   ],
   "source": [
    "bgn = now()\n",
    "vector_store_from_client = Chroma(\n",
    "    client             = persistent_client,\n",
    "    collection_name    = environ[\"_RAG_DOC_DBASE\"],\n",
    "    embedding_function = local_embeddings,\n",
    ")\n",
    "print( f\"Built vector store in {(now()-bgn)} seconds!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737c44ed-8f4b-42ac-9ca4-58ee7ba717a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore      = Chroma.from_documents( documents = pages, embedding = local_embeddings )\n",
    "# print( f\"Built vector store in {now()-bgn} seconds!\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e6145-9920-480b-bdd5-662cafd95a20",
   "metadata": {},
   "source": [
    "### 2024-10-18: Langchain's API Key fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0be8676-37ba-46ec-9159-0fc483c31bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# _UNSTRUCT_KEY_LOC = \"secrets/Langchain_Unstructured.txt\"\n",
    "\n",
    "# with open( _UNSTRUCT_KEY_LOC, 'r' ) as f:\n",
    "#     os.environ[\"UNSTRUCTURED_API_KEY\"] = str( f.read() ).strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f444a563-5f62-4263-af6b-6b25afd2a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "# loader = UnstructuredLoader(\n",
    "#     file_path = file_path,\n",
    "#     strategy  = \"hi_res\",\n",
    "#     partition_via_api = True,\n",
    "#     coordinates = True,\n",
    "# )\n",
    "# docs = []\n",
    "# for doc in loader.lazy_load():\n",
    "#     docs.append( doc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbbd76-0060-4ecd-abc7-ca748060fe84",
   "metadata": {},
   "source": [
    "### https://python.langchain.com/docs/how_to/document_loader_pdf/#local-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346f4c39-e60f-43ca-98d3-13329dca953c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_unstructured\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredLoader\n\u001b[1;32m      3\u001b[0m loader_local \u001b[38;5;241m=\u001b[39m UnstructuredLoader(\n\u001b[0;32m----> 4\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[43mfile_path\u001b[49m,\n\u001b[1;32m      5\u001b[0m     strategy  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfast\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#\"hi_res\",\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m docs_local \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m loader_local\u001b[38;5;241m.\u001b[39mlazy_load():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "loader_local = UnstructuredLoader(\n",
    "    file_path = file_path,\n",
    "    strategy  = \"fast\", #\"hi_res\",\n",
    ")\n",
    "docs_local = []\n",
    "for doc in loader_local.lazy_load():\n",
    "    docs_local.append( doc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c7bcf-4062-4c3f-a29c-251f2c73cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( docs_local )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9a2dc-a228-43c6-bd29-42247f7c9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "pull_ollama_model( \"llava\" )\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llava\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36bb78-3e01-46c5-a13a-52a354f7661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def pdf_page_to_base64(pdf_path: str, page_number: int):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    page = pdf_document.load_page(page_number - 1)  # input is one-indexed\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f24f6-ff61-4e95-b6e9-ac4fa22a5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "\n",
    "base64_image = pdf_page_to_base64(file_path, 11)\n",
    "display( IPImage( data = base64.b64decode( base64_image ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695b008-3cee-4cca-a754-cd4fc429a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What can be said about the data composition?\"\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": query},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "bgn = now()\n",
    "response = llm.invoke( [message] )\n",
    "print( f\"LLM query took {now()-bgn} seconds to process!\" )\n",
    "print( response.content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87af5cf-40b1-4912-ae69-fd7d04565a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1815ace-9adc-4c72-aaaf-d37d6f68ea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd0bce-e758-4e0b-a1b1-af1e361de2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7d09c-38fe-45de-8dd2-254a9914bd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fb173-ae41-46bb-b930-8cff12c68006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8ec26-bdc9-484e-b88d-e552b7bbee1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
